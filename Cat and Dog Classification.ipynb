{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db698b9b-d80d-4d67-9387-f43ff0961367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to directly use dataset watch : campusX (Cat Vs Dog Image Classification Project | Deep Learning Project | CNN Project), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c284cb91-6166-47f8-a508-1c2c5700e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78fd6f26-24aa-41cc-a77a-07c10ad640c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generators :\n",
    "# we use them so that it can load images in batches in RAM ,  and be fast ad efficient otherwise loading all \n",
    "# the data in RAM can slow the training and makes it difficult to perfomr well in low low RAM devices\n",
    "# Image data loading Keras documention : https://keras.io/api/data_loading/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4858bac-236f-443c-a1aa-3e78b73ed697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = keras.utils.image_dataset_from_directory(\n",
    "    directory = 'D:\\\\ML And DL datasets\\\\train',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size = 32,\n",
    "    image_size = (256,256)\n",
    ")\n",
    "\n",
    "test_dataset = keras.utils.image_dataset_from_directory(\n",
    "    directory = 'D:\\\\ML And DL datasets\\\\test',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',      # automatically label cat nad dogs diff numbers/labels\n",
    "    batch_size = 32,\n",
    "    image_size = (256,256)   # convert the images into (256,256) dim as all image's size are not same\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e98b9dc9-3d9d-41f6-b3b4-e52e8a7e0351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing images Dataset as images are in array form and each array contain value from 0 - 255\n",
    "def process(image,label):\n",
    "    image = tf.cast(image/255., tf.float32)\n",
    "    return image,label\n",
    "\n",
    "train_dataset = train_dataset.map(process)\n",
    "test_dataset = test_dataset.map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88775d3a-5319-465b-957e-8d072cbf6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
